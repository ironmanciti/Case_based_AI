{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 080. Simple RNN\n",
    "\n",
    "- Simple RNN을 이용한 **시계열 예측**\n",
    "\n",
    "<img src='time_prediction.png' width=40% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 Toy Data 생성 \n",
    "\n",
    "- sequence toy data로 sine wave 생성 (predictable 한 data point 생성)  \n",
    "- RNN은 시계열 Data 생성이 까다로움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [2], [3], [4]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [[i] for i in range(105)]\n",
    "numbers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input, label data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000],\n",
      "        [0.1100],\n",
      "        [0.1200],\n",
      "        [0.1300],\n",
      "        [0.1400]])\n",
      "tensor([0.3000])\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "target = []\n",
    "\n",
    "for i in range(5, len(numbers)):\n",
    "    data.append(numbers[i-5:i])\n",
    "    target.append(numbers[i][0] * 2)\n",
    "\n",
    "data = torch.tensor(data, dtype=torch.float) / 100\n",
    "target = torch.tensor(target, dtype=torch.float).unsqueeze(1) / 100\n",
    "print(data[10])\n",
    "print(target[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 5, 1]), torch.Size([100, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the RNN\n",
    "\n",
    "- `nn.RNN`을 사용하여 RNN 레이어를 생성한 다음, 원하는 출력 크기를 얻기 위해 fully-connected layer를 추가  \n",
    "\n",
    "- RNN의 parameters:  \n",
    "\n",
    "    * **input_size** - input X의 feature 수\n",
    "    * **hidden_dim** - RNN 출력 및 hidden state의 neuron 수\n",
    "    * **n_layers** - RNN을 구성하는 레이어 수 (일반적으로 1-3 개) 1보다 크면 stacked RNN을 생성한다는 의미\n",
    "    * **batch_first** - RNN의 입력 / 출력이 첫 번째 차원으로 batch_size를 가질지 여부 (batch_size, seq_length, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, nonlinearity='relu')\n",
    "        self.fc  = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # x (batch_size, seq_length, input_size)\n",
    "        # hidden (n_layers, batch_size, hidden_dim)\n",
    "        # r_out (batch_size, time_step, hidden_size)\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # sequence-to-vector (last time step만 사용)\n",
    "        output = self.fc(r_out[:, -1, :])\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the input and output dimensions\n",
    "\n",
    "- 모델이 예상대로 작동하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size:  torch.Size([100, 1])\n",
      "Hidden state size:  torch.Size([2, 100, 10])\n"
     ]
    }
   ],
   "source": [
    "# test that dimensions \n",
    "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
    "\n",
    "# test out rnn sizes\n",
    "test_out, test_h = test_rnn(data, None)  #None - hidden 초기화\n",
    "\n",
    "print('Output size: ', test_out.size())\n",
    "print('Hidden state size: ', test_h.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the RNN\n",
    "\n",
    "- 지정된 하이퍼 파라미터를 사용하여 RNN을 인스턴스화 및 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(1, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "input_size=1 \n",
    "output_size=1\n",
    "hidden_dim=32\n",
    "n_layers=1\n",
    "\n",
    "# instantiate an RNN\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after step 0 = 0.9884064197540283 \n",
      "Loss after step 100 = 0.027350950986146927 \n",
      "Loss after step 200 = 0.03234822675585747 \n",
      "Loss after step 300 = 0.037669576704502106 \n",
      "Loss after step 400 = 0.012614138424396515 \n",
      "Loss after step 500 = 0.016183825209736824 \n",
      "Loss after step 600 = 0.027250271290540695 \n",
      "Loss after step 700 = 0.00530839990824461 \n",
      "Loss after step 800 = 0.024165144190192223 \n",
      "Loss after step 900 = 0.011629397049546242 \n"
     ]
    }
   ],
   "source": [
    "n_steps = 1000\n",
    "print_every = 100\n",
    "\n",
    "# initialize the hidden state\n",
    "hidden = None      \n",
    "\n",
    "for step in range(n_steps):\n",
    "\n",
    "    prediction, hidden = rnn(data, hidden)\n",
    "\n",
    "    ## Representing Memory ##\n",
    "    # make a new variable for hidden and detach the hidden state from its history\n",
    "    # this way, we don't backpropagate through the entire history\n",
    "    hidden = hidden.data\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = criterion(prediction, target)\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    # perform backprop and update weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # display loss and predictions\n",
    "    if step % print_every == 0:        \n",
    "        print('Loss after step {1} = {0} '.format(loss.item(),  step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = torch.tensor([[35], [36], [37], [38], [39]], dtype=torch.float).unsqueeze(0) / 100\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7727, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict, _ = rnn(test_data, None)\n",
    "predict[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('tf20': conda)",
   "language": "python",
   "name": "python37564bittf20condadea3cb99c47a4fadb6986afca4b98e1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
